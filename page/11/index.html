<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>幻舞梦境</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="幻舞梦境">
<meta property="og:url" content="http://ovwane.me/page/11/index.html">
<meta property="og:site_name" content="幻舞梦境">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="幻舞梦境">
  
    <link rel="alternative" href="/atom.xml" title="幻舞梦境" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/favicon.png">
  
  
      <link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.5.0/animate.min.css">
  
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">
  <link rel="apple-touch-icon" href="/apple-touch-icon.png">
  
     
      <meta name="baidu-site-verification" content="3rC08I0Cp6" />
    
     
      <meta name="google-site-verification" content="rn8f25RzFQoiByt8ezg9E17KZIElbIlwJ4y-EKSlWbA" />
    
  
  
      <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  
  <!-- 加载特效 -->
    <script src="/js/pace.js"></script>
    <link href="/css/pace/pace-theme-flash.css" rel="stylesheet" />
  <script>
      var yiliaConfig = {
          rootUrl: '/',
          fancybox: true,
          animate: true,
          isHome: true,
          isPost: false,
          isArchive: false,
          isTag: false,
          isCategory: false,
          open_in_new: false
      }
  </script>
</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            
            <img lazy-src="/img/head.jpg" class="js-avatar">
            
        </a>

        <hgroup>
          <h1 class="header-author"><a href="/" title="Hi Mate">幻舞梦境</a></h1>
        </hgroup>

        
        
        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/">首页</a></li>
                        
                            <li><a href="/WebGuide">导航</a></li>
                        
                            <li><a href="/ovwane_love">Love</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fl github" target="_blank" href="https://github.com/ovwane" title="github">github</a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <a href="/tags/Ansible/" style="font-size: 11.67px;">Ansible</a> <a href="/tags/Bind/" style="font-size: 10px;">Bind</a> <a href="/tags/Cacti/" style="font-size: 10px;">Cacti</a> <a href="/tags/CentOS/" style="font-size: 20px;">CentOS</a> <a href="/tags/Cobbler/" style="font-size: 10px;">Cobbler</a> <a href="/tags/DHCP/" style="font-size: 10px;">DHCP</a> <a href="/tags/Django/" style="font-size: 13.33px;">Django</a> <a href="/tags/Docker/" style="font-size: 10px;">Docker</a> <a href="/tags/Elasticsearch/" style="font-size: 10px;">Elasticsearch</a> <a href="/tags/Git/" style="font-size: 10px;">Git</a> <a href="/tags/Gitlab/" style="font-size: 11.67px;">Gitlab</a> <a href="/tags/HAProxy/" style="font-size: 10px;">HAProxy</a> <a href="/tags/Hexo/" style="font-size: 11.67px;">Hexo</a> <a href="/tags/Homebrew/" style="font-size: 10px;">Homebrew</a> <a href="/tags/Java/" style="font-size: 10px;">Java</a> <a href="/tags/Jenkins/" style="font-size: 11.67px;">Jenkins</a> <a href="/tags/KVM/" style="font-size: 10px;">KVM</a> <a href="/tags/Kubernetes/" style="font-size: 10px;">Kubernetes</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/MariaDB/" style="font-size: 10px;">MariaDB</a> <a href="/tags/MySQL/" style="font-size: 10px;">MySQL</a> <a href="/tags/NFS/" style="font-size: 10px;">NFS</a> <a href="/tags/Nagios/" style="font-size: 10px;">Nagios</a> <a href="/tags/Nginx/" style="font-size: 16.67px;">Nginx</a> <a href="/tags/Oh-My-Zsh/" style="font-size: 10px;">Oh My Zsh</a> <a href="/tags/OpenLDAP/" style="font-size: 10px;">OpenLDAP</a> <a href="/tags/OpenStack/" style="font-size: 10px;">OpenStack</a> <a href="/tags/PHP/" style="font-size: 11.67px;">PHP</a> <a href="/tags/PXE/" style="font-size: 10px;">PXE</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/RHEL7/" style="font-size: 10px;">RHEL7</a> <a href="/tags/Redis/" style="font-size: 10px;">Redis</a> <a href="/tags/Requests/" style="font-size: 10px;">Requests</a> <a href="/tags/Resin/" style="font-size: 10px;">Resin</a> <a href="/tags/Samba/" style="font-size: 10px;">Samba</a> <a href="/tags/Scrapy/" style="font-size: 11.67px;">Scrapy</a> <a href="/tags/Scrapyd/" style="font-size: 10px;">Scrapyd</a> <a href="/tags/SpiderKeeper/" style="font-size: 10px;">SpiderKeeper</a> <a href="/tags/Squid/" style="font-size: 10px;">Squid</a> <a href="/tags/Subversion/" style="font-size: 10px;">Subversion</a> <a href="/tags/Supervisor/" style="font-size: 10px;">Supervisor</a> <a href="/tags/Tomcat/" style="font-size: 13.33px;">Tomcat</a> <a href="/tags/Ubuntu/" style="font-size: 10px;">Ubuntu</a> <a href="/tags/Web/" style="font-size: 10px;">Web</a> <a href="/tags/Xadmin/" style="font-size: 10px;">Xadmin</a> <a href="/tags/Zabbix/" style="font-size: 10px;">Zabbix</a> <a href="/tags/cacti/" style="font-size: 10px;">cacti</a> <a href="/tags/dovecot/" style="font-size: 10px;">dovecot</a> <a href="/tags/httpd/" style="font-size: 11.67px;">httpd</a> <a href="/tags/iSCSI/" style="font-size: 10px;">iSCSI</a> <a href="/tags/k8s/" style="font-size: 10px;">k8s</a> <a href="/tags/kickstart/" style="font-size: 10px;">kickstart</a> <a href="/tags/macOS/" style="font-size: 15px;">macOS</a> <a href="/tags/nagios/" style="font-size: 10px;">nagios</a> <a href="/tags/postfix/" style="font-size: 10px;">postfix</a> <a href="/tags/rsync/" style="font-size: 10px;">rsync</a> <a href="/tags/sshd/" style="font-size: 10px;">sshd</a> <a href="/tags/uWSGI/" style="font-size: 10px;">uWSGI</a> <a href="/tags/vsftpd/" style="font-size: 10px;">vsftpd</a> <a href="/tags/zabbix/" style="font-size: 10px;">zabbix</a> <a href="/tags/历史/" style="font-size: 18.33px;">历史</a> <a href="/tags/情感/" style="font-size: 10px;">情感</a> <a href="/tags/监控/" style="font-size: 13.33px;">监控</a> <a href="/tags/自己/" style="font-size: 10px;">自己</a> <a href="/tags/运维/" style="font-size: 10px;">运维</a>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a target="_blank" class="main-nav-link switch-friends-link" href="http://luuman.github.io/">name</a>
                    
                    </div>
                </section>
                

                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">纯海迷、爱运动、爱交友、爱旅行、喜欢接触新鲜事物、迎接新的挑战，更爱游离于错综复杂的编码与逻辑中</div>
                </section>
                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="Me">幻舞梦境</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                
                    <img lazy-src="/img/head.jpg" class="js-avatar">
                
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="Me">幻舞梦境</a></h1>
            </hgroup>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/">首页</a></li>
                
                    <li><a href="/WebGuide">导航</a></li>
                
                    <li><a href="/ovwane_love">Love</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                <div class="social">
                    
                        <a class="github" target="_blank" href="https://github.com/ovwane" title="github">github</a>
                    
                </div>
            </nav>
        </header>                
    </div>
</nav>
      <div class="body-wrap">
  
    <article id="post-Pyhont学习网站" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2018/07/12/Pyhont学习网站/" class="article-date">
      <time datetime="2018-07-12T05:51:19.279Z" itemprop="datePublished">2018-07-12</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p><a href="http://bbs.fishc.com/forum-173-1.html" target="_blank" rel="noopener">鱼C工作室-Python教学</a></p>
<p><a href="https://cuiqingcai.com/" target="_blank" rel="noopener">静觅丨崔庆才的个人博客</a></p>
<p><a href="https://www.lijinlong.cc/fuwuqi/hjpz/1962.html" target="_blank" rel="noopener">Django、Python3、Nginx、uWSGI环境部署教程</a></p>

      
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Python 3.x模块" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2018/07/12/Python 3.x模块/" class="article-date">
      <time datetime="2018-07-12T05:51:19.279Z" itemprop="datePublished">2018-07-12</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>Python 模块</p>
<p><a href="https://docs.python.org/3/py-modindex.html" target="_blank" rel="noopener">Python 3.x Module Index</a></p>
<p>urllib</p>
<p>hashlib<br>cookielib<br>re</p>
<p>getpass<br>json<br>pickle<br>pickletools<br>functools<br>glob</p>
<h3 id="configparser"><a href="#configparser" class="headerlink" title="configparser"></a>configparser</h3><p><a href="http://blog.csdn.net/miner_k/article/details/77857292" target="_blank" rel="noopener"> python的ConfigParser模块</a></p>
<h3 id="logging"><a href="#logging" class="headerlink" title="logging"></a>logging</h3><p><a href="http://zmister.com/archives/213.html" target="_blank" rel="noopener">优雅地记录Python程序日志1：logging模块简介</a></p>
<p><a href="http://zmister.com/archives/217.html" target="_blank" rel="noopener">优雅地记录Python程序日志2：模块组件化日志记录器</a></p>
<p>os<br>sys<br>queue<br>random<br>socket<br>socketserver<br>threading<br>multiprocessing</p>
<p>第三方模块</p>
<p>Requests<br>Scrapy<br>Pillow<br>BeautifulSoup<br>lxml</p>
<h3 id="selenium"><a href="#selenium" class="headerlink" title="selenium"></a>selenium</h3><p>胡志恒<br><a href="http://www.cnblogs.com/fnng/" target="_blank" rel="noopener">虫师</a></p>
<p><a href="http://www.cnblogs.com/fnng/p/7797839.html" target="_blank" rel="noopener">Chrome headless 模式</a></p>
<p><a href="http://blog.csdn.net/zhaoxz1985/article/details/72780085" target="_blank" rel="noopener">Web接口开发与自动化测试基于Python语言–第1章</a></p>
<p><a href="http://blog.csdn.net/zhaoxz1985/article/details/72862466" target="_blank" rel="noopener">Web接口开发与自动化测试基于Python语言–第2章</a></p>

      
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Python+Web开发实战-董伟明-目录" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2018/07/12/Python+Web开发实战-董伟明-目录/" class="article-date">
      <time datetime="2018-07-12T05:51:19.279Z" itemprop="datePublished">2018-07-12</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>页码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">486 第15章 Web 开发项目实践</span><br></pre></td></tr></table></figure>
      
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Python+Web开发实战-董伟明-笔记" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2018/07/12/Python+Web开发实战-董伟明-笔记/" class="article-date">
      <time datetime="2018-07-12T05:51:19.279Z" itemprop="datePublished">2018-07-12</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>页码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">486 第15章 Web 开发项目实践</span><br></pre></td></tr></table></figure>
      
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Shell高级编程实战-笔记" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2018/07/12/Shell高级编程实战-笔记/" class="article-date">
      <time datetime="2018-07-12T05:51:19.279Z" itemprop="datePublished">2018-07-12</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h2 id="01-Shell高级编程实战（第一、二部）"><a href="#01-Shell高级编程实战（第一、二部）" class="headerlink" title="01.Shell高级编程实战（第一、二部）"></a>01.Shell高级编程实战（第一、二部）</h2><p>10:00</p>
<blockquote>
<p>我一定要做到！我一定会做到！我一定能做到！</p>
</blockquote>
<p>原定的目标，学习两天课程后所达到的目标。</p>
<p>培训，投资是值得的。老男孩30岁之前挣的所有钱，31岁就全部挣回来了。</p>
<p>老男孩学习的方向：销售，演说，领导力，心理学，股改（股份制改造），易经之道</p>
<p>换框架：只定位运维，定位为架构师，定位为总监，定位为cto，定位为经理人。</p>
<p>开口说：谁想上台讲一讲？</p>
<p>花那么多钱，要有突破啊！</p>
<p>目标，目标分解。<br>学习方法，销售的七步曲。销的是自己，售的是产品。<br>勤奋，你要想成功，就要吃苦努力。<br>坚持，</p>
<p>产品包装，<br>行动，你们知道了，我们做到了。</p>
<p>紧张是正常的，不紧张才不正常。<br>多多锻炼，没有会，</p>
<p>Shell 脚本高级编程实战</p>
<p>2016-1-8 19:08</p>
<p>脑子里没东西，只会shell的语法。</p>
<p>运维需要会Shell和Python</p>
<p>学习Shell的基础</p>
<ol>
<li>vim编辑器 ssh终端，.vimrc配置熟悉</li>
<li>命令基础：Linux的150个常用命令的熟练使用。</li>
<li>linux正则表达式以及三剑客（grep、sed、awk）要熟练了。</li>
<li>常见linux网络服务部署、优化及排错。</li>
</ol>
<p><em>学习shell编程，我们这几天学完后需要达到什么样的目标？</em></p>
<p>3天时间</p>
<p>你会了不叫会，你会了然后教会别人才叫会。 </p>
<p>想不想 想</p>
<p><a href="06.Shell高级编程实战（第十一、十二部）">linux运维22道企业必会Shell编程面试题实战精讲</a></p>
<p>老男孩写的运维班6本书<br>命令基础<br>linux基础<br>中小型集群架构<br>数据库<br>shell编程<br>大型网站集群架构实战</p>
<p>什么是Shell？<br>命令解释器，使用者和内核沟通的桥梁。<br>什么是Shell脚本？<br>命令、变量、流程控制语句等有机结合起来就是一个功能强大的shell脚本。</p>
<p>知识就是财富。</p>
<p>今天你花钱学习，明天你的知识变更多的钱。</p>
<p>清空系统日志</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"><span class="comment"># 清除日志脚本，版本 1</span></span><br><span class="line"><span class="comment">#日志存放目录</span></span><br><span class="line">LOG_DIR=/var/<span class="built_in">log</span></span><br><span class="line"><span class="comment">#$UID为0的时候，用户才具有root用户的权限</span></span><br><span class="line">ROOT_UID=0</span><br><span class="line"><span class="comment">#判断是否root用户运行此脚本</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$UID</span>"</span> -ne <span class="string">"ROOT_UID"</span> ]; <span class="keyword">then</span></span><br><span class="line">	<span class="built_in">echo</span> <span class="string">"Must be root user to run this script."</span></span><br><span class="line">	<span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$LOD_DIR</span> || &#123;</span><br><span class="line">	<span class="built_in">echo</span> <span class="string">"cannot change to necessary directory."</span>&gt;&amp;2</span><br><span class="line">	<span class="built_in">exit</span> 1</span><br><span class="line">&#125;</span><br><span class="line">cat /dev/null &gt; messages &amp;&amp; <span class="built_in">echo</span> <span class="string">"Logs cheaned up."</span></span><br><span class="line"><span class="comment">#退出之前返回0表示成功，返回1表示失败</span></span><br><span class="line"><span class="built_in">exit</span> 0</span><br></pre></td></tr></table></figure>
<p>总结</p>
<ol>
<li>必须是root才能执行脚本，否则退出。</li>
<li>成功切换目录，否则退出。</li>
<li>清理日志，清理成功，在输出。</li>
<li>完成。</li>
</ol>
<p>一定要牛逼起来，老男孩说。</p>
<p>没有人能随随便便成功，不经历风雨怎么能成功。</p>
<p>Shell脚本很擅长处理纯文本类型的数据</p>
<p>脚本语言的种类<br>Bourne shell（sh）<br>csh<br>ksh<br>Bourne Again shell（bash）<br>zsh</p>
<p>文件测试表达式<br>测试的对象可以是文件，字符串，数字等。</p>
<p>文件测试操作符<br>-f 文件存在且为普通文件为真，<br>-d 文件存在且为目录文件为真，<br>-s 文件存在且文件大小不为0为真，<br>-e 文件存在为真，只要有文件就行，要区别-f<br>-r 文件存在且可读为真，<br>-w 文件存在且可写为真，<br>-x 文件存在且可执行为真，<br>-L 文件存在且为链接文件为真，<br>f1 -nt f2 文件f1比文件f2新为真，根据文件修改时间计算nt=newer than<br>f1 -ot f2 文件f1比文件f2旧为真，根据文件修改时间计算ot=older than<br>特别说明：这些操作符号对于[[]]、[]、test几乎是通用的<br>查询 man test</p>
<blockquote>
<p>努力很重要，3万左右的工资。努力做。（不要努力做吧！）</p>
</blockquote>
<p>字符串表达式<br>-n “str” 字符串长度不为0为真，<br>-z “str” 长度为0为真<br>“str1” = “str2”<br>“str1” != “str2”</p>
<p>特别说明：<br>字符串要用双引号包起来，等号两端需要空格。<br>参考:<br>/etc/init.d/rpcbind<br>/etc/init.d/nfs</p>
<p>整数二元比较操作符<br>-eq 等于<br>-ne 不等于<br>-gt 大于<br>-ge 大于等于<br>-lt 小于<br>-le 小于等于</p>
<p>[ 1 -eq 2 ]<br>[[ 1 -eq 2 ]]</p>
<p>工作用 [] -eq的用法</p>
<blockquote>
<p>和女生吵架不行的，不要辩解对与错。</p>
</blockquote>
<p>逻辑操作符<br>条件表达式<br>[在单括号中使用] [[在双括号中使用]] 说明<br>-a &amp;&amp;  and与，两端都为真，则真，相当于乘法<br>-o || or或，两端有一个为真则真，相当于加法<br>! ! not非，相反则为真</p>
<p>学习，学会之前比，不要去变通。学会之后再去做变通。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#输入</span></span><br><span class="line"><span class="built_in">read</span> -p “please input two num：<span class="string">" num1 num2</span></span><br><span class="line"><span class="string">a=<span class="variable">$num1</span></span></span><br><span class="line"><span class="string">b=<span class="variable">$num2</span></span></span><br><span class="line"><span class="string">#判断输入参数的个数</span></span><br><span class="line"><span class="string">[ <span class="variable">$#</span> -ne 2 ]&amp;&amp;&#123;</span></span><br><span class="line"><span class="string">	echo "</span>USAGE: num1 num2<span class="string">"</span></span><br><span class="line"><span class="string">	exit 1</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">[ -z "</span><span class="variable">$a</span><span class="string">" -o -z "</span><span class="variable">$b</span><span class="string">" ]&amp;&amp;&#123;</span></span><br><span class="line"><span class="string">	echo "</span>USAGE: num1 num2<span class="string">"</span></span><br><span class="line"><span class="string">	exit 1</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">#判断输入是否整数</span></span><br><span class="line"><span class="string">[ "</span> <span class="built_in">echo</span> <span class="string">"<span class="variable">$1</span>"</span>|sed -r <span class="string">'s#[^0-9]##g'</span> <span class="string">" = "</span><span class="variable">$1</span><span class="string">" ]||&#123;</span></span><br><span class="line"><span class="string">	echo "</span>first args must be int.<span class="string">"</span></span><br><span class="line"><span class="string">	exit 2</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">[ "</span> <span class="built_in">echo</span> <span class="string">"<span class="variable">$2</span>"</span>|sed -r <span class="string">'s#[^0-9]##g'</span> <span class="string">" = "</span><span class="variable">$2</span><span class="string">" ]||&#123;</span></span><br><span class="line"><span class="string">	echo "</span>second args must be int.<span class="string">"</span></span><br><span class="line"><span class="string">	exit 2</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">#判断</span></span><br><span class="line"><span class="string">[ <span class="variable">$1</span> -lt <span class="variable">$2</span>]&amp;&amp;&#123;</span></span><br><span class="line"><span class="string">	echo "</span><span class="variable">$1</span>&lt;<span class="variable">$2</span><span class="string">"</span></span><br><span class="line"><span class="string">	exit 0</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">[ <span class="variable">$1</span> -eq <span class="variable">$2</span>]&amp;&amp;&#123;</span></span><br><span class="line"><span class="string">	echo "</span><span class="variable">$1</span>=<span class="variable">$2</span><span class="string">"</span></span><br><span class="line"><span class="string">	exit 0</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">[ <span class="variable">$1</span> -gt <span class="variable">$2</span>]&amp;&amp;&#123;</span></span><br><span class="line"><span class="string">	echo "</span><span class="variable">$1</span>&gt;<span class="variable">$2</span><span class="string">"</span></span><br><span class="line"><span class="string">	exit 0</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure>
<p>vim替换 ESC模式 :%s###g</p>
<p>打印选择菜单</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">menu</span></span>()&#123;</span><br><span class="line">cat &lt;&lt;EOF</span><br><span class="line">1.</span><br><span class="line">2.</span><br><span class="line">3.[<span class="built_in">exit</span>]</span><br><span class="line">EOF</span><br><span class="line">&#125;</span><br><span class="line">menu</span><br><span class="line"><span class="built_in">read</span> -p <span class="string">""</span> num</span><br><span class="line">[ <span class="variable">$num</span> -eq 1 ]&amp;&amp;&#123;</span><br><span class="line">	<span class="built_in">echo</span> <span class="string">"start install"</span></span><br><span class="line">	[ -x lamp.sh ]||exit2</span><br><span class="line">	sh lamp.sh</span><br><span class="line">	<span class="built_in">exit</span> 0</span><br><span class="line">&#125;</span><br><span class="line">[ <span class="variable">$num</span> -eq 2 ]&amp;&amp;&#123;</span><br><span class="line">	</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"input error"</span></span><br><span class="line"><span class="built_in">exit</span> 2</span><br></pre></td></tr></table></figure>
<p>分支与循环结果<br>if单分支结构</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [];<span class="keyword">then</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<p>if双分支结构</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [];<span class="keyword">then</span></span><br><span class="line"><span class="keyword">else</span> []</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<p>if多分支结构</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [] ;<span class="keyword">then</span></span><br><span class="line"><span class="keyword">elif</span> [];<span class="keyword">then</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<p>判断系统剩余内存大小，如果低于100M就邮件报警给管理员，并且加入系统定时任务每3分钟执行一次检查</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">mem=$(free -m|grep Mem:|awk <span class="string">'&#123;print $4&#125;'</span>)</span><br><span class="line"><span class="keyword">if</span> [  <span class="variable">$men</span> -lt 100 ];<span class="keyword">then</span></span><br><span class="line">	send mail</span><br><span class="line">	crontab -e &lt;<span class="built_in">echo</span> <span class="string">"*/3 * * * * /bin/bash check_mem.sh"</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#第一步：获取内存大小</span></span><br><span class="line">free -m|awk <span class="string">'NR==3&#123;print $NF&#125;'</span></span><br><span class="line"><span class="comment">#第二步：配置邮件</span></span><br><span class="line"><span class="built_in">echo</span> <span class="built_in">set</span> from=@qq.com smtp= &gt;/etc/mail.rc</span><br><span class="line"><span class="comment">#第三步：定时任务</span></span><br><span class="line">tail -2 /var/spool/cron/root</span><br><span class="line"></span><br><span class="line">*/3 * * * * /bin/sh /free.sh &amp;&gt;/dev/null</span><br><span class="line"></span><br><span class="line">free=$(free -m|awk <span class="string">'NR==3&#123;print $NF&#125;'</span>)</span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$free</span> -lt 100 ];<span class="keyword">then</span></span><br><span class="line">	<span class="built_in">echo</span> <span class="string">"当前内存<span class="variable">$free</span>不够，发送邮件"</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">	<span class="built_in">echo</span> <span class="string">"当前内存<span class="variable">$free</span>够用</span></span><br><span class="line"><span class="string">fi</span></span><br></pre></td></tr></table></figure>
<p>发送邮件mail mutt</p>
<p>老男孩写的</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cur_free=`free -m|awk <span class="string">'/buffers\// &#123;print $NF&#125;'</span>`</span><br></pre></td></tr></table></figure>
<p>徐亮伟 架构师之路QQ群 471443208</p>
<blockquote>
<p>要么工资很高，要么公司不要你。</p>
</blockquote>
<p>扩展：监控磁盘，NFS系统，MySQL，Web</p>
<p><code>netstat -lnt|grep 3306|wc -l</code><br><code>netstat -lntup|grep mysqld|wc -l</code></p>
<p>用 if双分支实现对nginx或mysql</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [`ss -lntup|grep 80|wc -l` -ne 0 ] <span class="keyword">then</span></span><br><span class="line">	<span class="built_in">echo</span> <span class="string">"httpd is stared."</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">	<span class="built_in">echo</span> <span class="string">"http is not start."</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [ $(ss -lntup|grep mysqld|wc -l) -ge 1 ]; <span class="keyword">then</span></span><br><span class="line">	<span class="built_in">echo</span> <span class="string">""</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [ `ps -ef|grep <span class="string">"nginx"</span>|egrep -v <span class="string">"php-fpm"</span>|wc -l` -ge 2 ];<span class="keyword">then</span> <span class="comment">#ps -ef 可以用 ps -C（去除第一行)</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">action <span class="string">"mysql"</span> /bin/ture &amp;&amp; <span class="built_in">exit</span> 0</span><br></pre></td></tr></table></figure>
<p>监控web服务和db服务<br>netstat/ss/lsof<br>telnet/nmap/nc</p>
<p>字符串比较 3306</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">netstat -lntup|grep 3306|wc -l</span><br><span class="line">lsof -i :3306|grep 3306|wc -l</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nmap www.baidu.com -p 80|grep open|wc -l</span><br><span class="line">nc -w 5</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -ef|grep mysql|wc -l</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget</span><br><span class="line">curl</span><br></pre></td></tr></table></figure>
<p>header(http)<br>数据库客户端连接</p>
<p><a href="http://oldboy.blog.51cto.com/2561410/942530" target="_blank" rel="noopener">查看远端的端口是否通畅3个简单实用案例！</a><br><a href="http://oldboy.blog.51cto.com/2561410/1196298" target="_blank" rel="noopener">思想</a></p>
<p>web check</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [ <span class="string">"`curl -I -s -o /dev/null -w "</span>%&#123;http_code&#125;\n<span class="string">" http://www.baidu.com`"</span> == <span class="string">"200"</span> ]</span><br><span class="line"><span class="keyword">if</span> [ `curl -I http://www. baidu.com 2&gt;/dev/null|head -1|grep 200|wc -l` -eq 1 ]</span><br><span class="line">curl -s http://www.baidu.com &amp;&gt;/dev/null</span><br><span class="line"><span class="keyword">if</span> [ $? -eq 0 ]</span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"`curl -s http://www.baidu.com &amp;&gt;/dev/null&amp;&amp;echo $?`"</span> = <span class="string">"0"</span> ]</span><br></pre></td></tr></table></figure>
<p><code>wget -T 10 -q --spider http://www.baidu.com &gt;/dev/null</code><br><code>curl -o /dev/null -s baidu.com -w &quot;%{http_code}\n&quot;</code></p>
<p><a href="http://blog.itpub.net/22661144/viewspace-1974005/" target="_blank" rel="noopener">企业生产案例：批量创建目录并移动带日期文件到相应目录</a></p>
<p><a href="http://blog.itpub.net/22661144/viewspace-1973710/" target="_blank" rel="noopener">监控目录备份是否成功通过脚本backup_monitor.sh</a></p>
<blockquote>
<p>拍马屁，要会拍马屁。</p>
</blockquote>
<p>女生感性动物。打动她。</p>
<p>运维思想：<br>三国，马谡怎么得到街亭的offer。<br>诸葛亮相信他。</p>
<p>怎么让面试官相信呢？</p>
<p>七擒孟获，马谡谏言，甚得诸葛之心。解决相信问题。</p>
<blockquote>
<p>对的，运维思想，很重要。技术再强，比不上做人做事。当然有技术是前提，否则就进不去。</p>
</blockquote>
<p>马谡解决了让诸葛亮相信的问题，拿到了守街亭的offer。</p>
<p>结果不听领导话，结果丢了工作和head。</p>
<p>实现通过传参的方式往/etc/user.conf里添加用户，具体要求<br>1）命令用法：<br>sh adduser {-add|-del|-search} username<br>2）传参要求：<br>如果参数为-add时，表示添加后面接的用户名。<br>如果参数为-del时，表示删除后面接的用户名。<br>如果参数为-search时，表示查找后面接的用户名。<br>3）如果有同名的用户则不能添加，没有对应用户则无需删除，查找到用户以及没有用户时给出明确提示。<br>4）/etc/user.conf不能被所欲外部用户直接删除及修改</p>
<blockquote>
<p>没什么卵用，然并卵</p>
</blockquote>
<p>判断字符串是否为数字的多种思路<br>sed 加正则表达式<br>sed ‘s/[0-9]//g’</p>
<p>expr()<br>expr $a+$b + 1 &amp;&gt;/dev/null</p>
<p>判断字符串长度是不是为0的多种思路</p>
<ol>
<li>字符串-z -n表达式</li>
<li>变量</li>
<li>expr<br><code>expr length &quot;&quot;</code> -eq 0</li>
<li>wc<br><code>wc -l</code> -eq 0</li>
<li>awk length函数</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [[ <span class="variable">$b</span> =~^[0-9]+$ ]]</span><br></pre></td></tr></table></figure>
<p>echo “1d”|bc</p>
<p>监控memcache服务是否正常，模拟用户（web客户端）检测。<br>使用nc命令加上set/get来模拟检测。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">printf</span> <span class="string">"del key\r\n"</span>|nc 127.0.0.1 112111 &amp;&gt;/dev/null</span><br><span class="line"><span class="built_in">printf</span> <span class="string">"set key 0 0 10 \r\nboy\r\n"</span>|nc 127.0.0.1 11211 &amp;&gt;/dev/null</span><br><span class="line">McValues=`<span class="built_in">printf</span> <span class="string">"get key \r\n"</span>|nc 127.0.0.1 11211|grep oldboy|wc -l`</span><br><span class="line"><span class="keyword">if</span> [<span class="variable">$McValues</span> -eq 1 ];<span class="keyword">then</span></span><br><span class="line">	<span class="built_in">echo</span> <span class="string">"memcached status is ok"</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<p>监控memcached服务、命中hit率、响应时间</p>
<p>生产环境监控MySQL服务的实战例子<br>python|php 去连接mysql 查询</p>
<p>监控MySQL数据库是否异常的多种方法<br>1、监控MySQL端口号<br><code>netstat -lntup|grep 3306|wc -l|</code><br><code>lsof -i :3306|wc -l</code><br>telnet/nc/nmap<br><code>ps -ef|grep mysql|grep -v grep|wc -l</code><br>2、通过客户端命令<br><code>mysql -uroot -p -e &quot;select version();&quot;&amp;&gt;/dev/null</code><br>通过php/java程序url方式监控MySQL<br>/etc/init.d/mysql status</p>
<p>监控web目录文件是否被篡改，如果被篡改则记录文件名</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">find /var/www/html -<span class="built_in">type</span> f |xargs md5sum&gt;/tmp/md5list</span><br><span class="line">md5sum -C /tmp/md5list</span><br></pre></td></tr></table></figure>
<p>如何查看远端web服务是否开通tcp 80端口？<br><code>telnet baidu.com 80</code></p>
<p>26期的fuzhu offer心得</p>
<p>技术聊，技术总监聊，HR聊，HR总监聊。</p>
<p>总监聊的。<br>公司的规划<br>对技术的细节<br>备份优化<br>自动化运维</p>
<p>说的比较有条理，并且引用了shell脚本。</p>
<p>小 人资聊，<br>聊，文中说了。几个聊</p>
<p>谈的是那个愉快。</p>
<p>个人积极性，对工作的积极性。</p>
<p>监控 系统优化 安全规划 负载均衡 Web服务器</p>
<p>Docker这块，我不懂。用来用去就那几个点。来了找着抄就行了。</p>
<p>监控，系统，安全规划，shell脚本，数据库有dba，数据库优化，lvs， haproxy，f5，做的负载均衡，apache，nginx，tomcat，开发上的东西，中间件。评价是还行。积极性。浮躁的心理。shell，优化。十拿九稳的必须会问。看个人的临场发挥。不同的人，不同的对应方法。</p>
<p>机器迁移，不要直接拷贝。新建环境。测试。迁移。</p>
<p>面试官问工作经历。逐条逐条问。自己简历自己写的。问到不会的话那还聊啥。回家吧。就像你去国美面试一样。</p>
<blockquote>
<p>态度，积极向上的人生态度。</p>
</blockquote>
<p>就算拿到offer，工作中做不了的话。那还是不行的。还是要被开除。</p>
<p>技术过硬才行。</p>
<blockquote>
<p>学过的东西表现的很扎实，掌握的很扎实。</p>
</blockquote>
<p>去练习</p>
<p>开发中间件</p>
<p>表现出工作的积极性，</p>
<h2 id="02-Shell高级编程实战（第三、四部）"><a href="#02-Shell高级编程实战（第三、四部）" class="headerlink" title="02.Shell高级编程实战（第三、四部）"></a>02.Shell高级编程实战（第三、四部）</h2><h2 id="03-Shell高级编程实战（第五、六部）"><a href="#03-Shell高级编程实战（第五、六部）" class="headerlink" title="03.Shell高级编程实战（第五、六部）"></a>03.Shell高级编程实战（第五、六部）</h2><p>马谡有让领导相信他的能力</p>
<p>要会表达，也要会做，理论联系实践，实践</p>
<p>第一印象很重要</p>
<p><a href="http://oldboy.blog.51cto.com/2561410/1706490" target="_blank" rel="noopener">要下山的徒弟必知必做的江湖规矩！</a></p>
<h2 id="04-Shell高级编程实战（第七、八部）"><a href="#04-Shell高级编程实战（第七、八部）" class="headerlink" title="04.Shell高级编程实战（第七、八部）"></a>04.Shell高级编程实战（第七、八部）</h2><p>01.课前思想-学会感恩会让自己的路越走越宽.mp4 26:34<br>02.Shellfor循环结构介绍及多个企业案例实践.mp4<br>03.Shell循环的控制命令介绍及区别实践对比.mp4<br>04.Shell循环的例子说明.mp4<br>05.Shell数组的介绍及实践.mp4<br>06.Shell数组的案例实践与数组核心总结.mp4<br>07.Shell22道企业案例精讲动员-讲解见后面.mp4<br>08.Shell脚本的调试方法及实践-(1).mp4 15:13<br>09.Shell脚本的调试方法及实践-(2).mp4<br>10.Shell脚本的调试方法及实践-(3).mp4<br>11.Shell脚本的调试方法及实践-(4).mp4<br>12.shell企业面试题讲解1-老男孩23期谢迪.mp4<br>13-shell企业面试题讲解2-老男孩23期李闯.mp4<br>14.shell企业面试题讲解1-老男孩23期王二麻.mp4<br>15.linux跳板机案例开发之trap信号知识分享讲解.mp4<br>16.linux跳板机案例实战开发分享讲解.mp4<br>17.linux跳板机使用安全方案分享讲解.mp4</p>
<h2 id="05-Shell高级编程实战（第九、十部）"><a href="#05-Shell高级编程实战（第九、十部）" class="headerlink" title="05.Shell高级编程实战（第九、十部）"></a>05.Shell高级编程实战（第九、十部）</h2><p>01.批量创建文件Shell编程手把手实战案例.mp4 06:02<br>02.批量创建用户及密码Shell编程手把手实战案例.mp4<br>03.批量修改文件名Shell编程手把手实战案例.mp4<br>04.破解RANDOM随机数md5sum后内容Shell编程手把手实战案例.mp4<br>05.企业案例-过滤固定长度单词手把手多案例实践.mp4<br>06.批量检查网站地址是否异常专业脚本开发实践.mp4<br>07.MySQL分库备份脚本实战讲解.mp4<br>08.MySQL分库分表备份脚本实战讲解.mp4<br>09.开发MySQL专业启动脚本手把手实战讲解.mp4<br>10.开发脚本防止DOS攻击自动封IP案例.mp4<br>11.开发专业监控MySQL主从复制故障手把手实战.mp4<br>12.中企动力面试题手把手实战讲解.mp4 15:03</p>
<h2 id="06-Shell高级编程实战（第十一、十二部）"><a href="#06-Shell高级编程实战（第十一、十二部）" class="headerlink" title="06.Shell高级编程实战（第十一、十二部）"></a>06.Shell高级编程实战（第十一、十二部）</h2><h2 id="07-Shell高级编程实战（第十三部）三剑客之sed实践讲解"><a href="#07-Shell高级编程实战（第十三部）三剑客之sed实践讲解" class="headerlink" title="07.Shell高级编程实战（第十三部）三剑客之sed实践讲解"></a>07.Shell高级编程实战（第十三部）三剑客之sed实践讲解</h2><h2 id="08-Shell高级编程实战（第十四部）AWK数组国内企业案例"><a href="#08-Shell高级编程实战（第十四部）AWK数组国内企业案例" class="headerlink" title="08.Shell高级编程实战（第十四部）AWK数组国内企业案例"></a>08.Shell高级编程实战（第十四部）AWK数组国内企业案例</h2><p>ping -W 2 -c 2<br>nmap -sP -sS<br>nc -w -z</p>

      
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Python分布式爬虫打造搜索引擎 学习笔记" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2018/07/12/Python分布式爬虫打造搜索引擎 学习笔记/" class="article-date">
      <time datetime="2018-07-12T05:51:19.279Z" itemprop="datePublished">2018-07-12</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="Python分布式爬虫打造搜索引擎"><a href="#Python分布式爬虫打造搜索引擎" class="headerlink" title="Python分布式爬虫打造搜索引擎"></a><a href="http://coding.imooc.com/class/92.html" target="_blank" rel="noopener">Python分布式爬虫打造搜索引擎</a></h1><h2 id="第1章-课程介绍"><a href="#第1章-课程介绍" class="headerlink" title="第1章 课程介绍"></a>第1章 课程介绍</h2><h4 id="介绍课程目标、通过课程能学习到的内容、和系统开发前需要具备的知识"><a href="#介绍课程目标、通过课程能学习到的内容、和系统开发前需要具备的知识" class="headerlink" title="介绍课程目标、通过课程能学习到的内容、和系统开发前需要具备的知识"></a>介绍课程目标、通过课程能学习到的内容、和系统开发前需要具备的知识</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Scrapy </span><br><span class="line">elasticsearch</span><br><span class="line">django</span><br></pre></td></tr></table></figure>
<h2 id="第2章-windows下搭建开发环境"><a href="#第2章-windows下搭建开发环境" class="headerlink" title="第2章 windows下搭建开发环境"></a>第2章 windows下搭建开发环境</h2><h4 id="介绍项目开发需要安装的开发软件、-python虚拟virtualenv和-virtualenvwrapper的安装和使用、-最后介绍pycharm和navicat的简单使用"><a href="#介绍项目开发需要安装的开发软件、-python虚拟virtualenv和-virtualenvwrapper的安装和使用、-最后介绍pycharm和navicat的简单使用" class="headerlink" title="介绍项目开发需要安装的开发软件、 python虚拟virtualenv和 virtualenvwrapper的安装和使用、 最后介绍pycharm和navicat的简单使用"></a>介绍项目开发需要安装的开发软件、 python虚拟virtualenv和 virtualenvwrapper的安装和使用、 最后介绍pycharm和navicat的简单使用</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">PyCharm安装和配置</span><br><span class="line">MySQL和Navicat的安装使用</span><br><span class="line">CentOS安装Python2和Python3</span><br><span class="line">Python虚拟环境的安装配置virtualenv、virtualenvwrapper</span><br></pre></td></tr></table></figure>
<h2 id="第3章-爬虫基础知识回顾"><a href="#第3章-爬虫基础知识回顾" class="headerlink" title="第3章 爬虫基础知识回顾"></a>第3章 爬虫基础知识回顾</h2><h4 id="介绍爬虫开发中需要用到的基础知识包括爬虫能做什么，正则表达式，深度优先和广度优先的算法及实现、爬虫url去重的策略、彻底弄清楚unicode和utf8编码的区别和应用。"><a href="#介绍爬虫开发中需要用到的基础知识包括爬虫能做什么，正则表达式，深度优先和广度优先的算法及实现、爬虫url去重的策略、彻底弄清楚unicode和utf8编码的区别和应用。" class="headerlink" title="介绍爬虫开发中需要用到的基础知识包括爬虫能做什么，正则表达式，深度优先和广度优先的算法及实现、爬虫url去重的策略、彻底弄清楚unicode和utf8编码的区别和应用。"></a>介绍爬虫开发中需要用到的基础知识包括爬虫能做什么，正则表达式，深度优先和广度优先的算法及实现、爬虫url去重的策略、彻底弄清楚unicode和utf8编码的区别和应用。</h4><h5 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scrapy vs requests+beautifulsoup</span><br><span class="line">1.requests和beautifulsoup都是库，scrapy是框架</span><br><span class="line">2.scrapy框架中可以加入requests和beautifulsoup</span><br><span class="line">3.scarpy基于twisted，性能是最大的优势</span><br><span class="line">4.scarpy方便扩展，提供了很多内置的功能</span><br><span class="line">5.scrapy内置的css和xpath selector非常方便，beautifulsoup最大的缺点就是慢</span><br></pre></td></tr></table></figure>
<h5 id="网页分类"><a href="#网页分类" class="headerlink" title="网页分类"></a>网页分类</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">常见类型的服务</span><br><span class="line">1.静态网页</span><br><span class="line">2.动态网页</span><br><span class="line">3.webservice(restapi)</span><br></pre></td></tr></table></figure>
<h5 id="爬虫能做什么"><a href="#爬虫能做什么" class="headerlink" title="爬虫能做什么"></a>爬虫能做什么</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">爬虫作用</span><br><span class="line">1.搜索引擎---百度、google、垂直领域搜索引擎</span><br><span class="line">2.推荐引擎---今日头条</span><br><span class="line">3.机器学习的数据样本</span><br><span class="line">4.数据分析（如金融数据分析）、舆情分析等</span><br></pre></td></tr></table></figure>
<h4 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">目录</span><br><span class="line">1.特殊字符</span><br><span class="line">1)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="comment"># 待匹配字符串</span></span><br><span class="line">line = <span class="string">'ssfder'</span></span><br><span class="line"><span class="comment"># 匹配规则</span></span><br><span class="line">regex_str = <span class="string">"^b.*"</span></span><br><span class="line"><span class="comment"># 匹配字符</span></span><br><span class="line"><span class="keyword">if</span> re.match(regex_str, line):</span><br><span class="line">	print(<span class="string">"yes"</span>)</span><br></pre></td></tr></table></figure>
<h4 id="字符串编码"><a href="#字符串编码" class="headerlink" title="字符串编码"></a>字符串编码</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.ASCII</span><br><span class="line">2.Unicode</span><br><span class="line">3.可变长编码 utf-8</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">文件：test.txt utf-8编码---&gt;(read)读取：转换为unicode编码---&gt;(read)内存中 Unicode编码---&gt;(save)保存：转换为utf-8编码</span><br></pre></td></tr></table></figure>
<h4 id="爬虫去重策略"><a href="#爬虫去重策略" class="headerlink" title="爬虫去重策略"></a>爬虫去重策略</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.将访问过的url保存到数据库中</span><br><span class="line">2.将访问过的url保存到set中，只需要o(1)的代价就可以查询url 100000000*2byte*50个字符/1024/1024/1024 = 9GB </span><br><span class="line">3.url经过md5等方法哈希后保存到set中</span><br><span class="line">4.用bitmap方法，将访问过的url通过hash函数映射到某一位</span><br><span class="line">5.bloomfilter方法对bitmap进行改进，多重hash函数降低冲突</span><br></pre></td></tr></table></figure>
<h4 id="深度优先和广度优先"><a href="#深度优先和广度优先" class="headerlink" title="深度优先和广度优先"></a>深度优先和广度优先</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">目录</span><br><span class="line">1.网站的树结构</span><br><span class="line">2.深度优先算法和实现</span><br><span class="line">递归实现</span><br><span class="line">3.广度优先算法和实现</span><br><span class="line">队列实现</span><br></pre></td></tr></table></figure>
<h2 id="第4章-scrapy爬取知名技术文章网站"><a href="#第4章-scrapy爬取知名技术文章网站" class="headerlink" title="第4章 scrapy爬取知名技术文章网站"></a>第4章 scrapy爬取知名技术文章网站</h2><h4 id="搭建scrapy的开发环境，本章介绍scrapy的常用命令以及工程目录结构分析，本章中也会详细的讲解xpath和css选择器的使用。然后通过scrapy提供的spider完成所有文章的爬取。然后详细讲解item以及item-loader方式完成具体字段的提取后使用scrapy提供的pipeline分别将数据保存到json文件以及mysql数据库中。…"><a href="#搭建scrapy的开发环境，本章介绍scrapy的常用命令以及工程目录结构分析，本章中也会详细的讲解xpath和css选择器的使用。然后通过scrapy提供的spider完成所有文章的爬取。然后详细讲解item以及item-loader方式完成具体字段的提取后使用scrapy提供的pipeline分别将数据保存到json文件以及mysql数据库中。…" class="headerlink" title="搭建scrapy的开发环境，本章介绍scrapy的常用命令以及工程目录结构分析，本章中也会详细的讲解xpath和css选择器的使用。然后通过scrapy提供的spider完成所有文章的爬取。然后详细讲解item以及item loader方式完成具体字段的提取后使用scrapy提供的pipeline分别将数据保存到json文件以及mysql数据库中。…"></a>搭建scrapy的开发环境，本章介绍scrapy的常用命令以及工程目录结构分析，本章中也会详细的讲解xpath和css选择器的使用。然后通过scrapy提供的spider完成所有文章的爬取。然后详细讲解item以及item loader方式完成具体字段的提取后使用scrapy提供的pipeline分别将数据保存到json文件以及mysql数据库中。…</h4><h4 id="xpath"><a href="#xpath" class="headerlink" title="xpath"></a>xpath</h4><h5 id="xpath简介"><a href="#xpath简介" class="headerlink" title="xpath简介"></a>xpath简介</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.xpath使用路径表达式在xml和html中进行导航</span><br><span class="line">2.xpath包含标准函数库</span><br><span class="line">3.xpath是一个w3c的标准</span><br></pre></td></tr></table></figure>
<h5 id="xpath节点关系"><a href="#xpath节点关系" class="headerlink" title="xpath节点关系"></a>xpath节点关系</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.父节点</span><br><span class="line">2.子节点</span><br><span class="line">3.同胞节点</span><br><span class="line">4.先辈节点</span><br><span class="line">5.</span><br></pre></td></tr></table></figure>
<h5 id="xpath语法"><a href="#xpath语法" class="headerlink" title="xpath语法"></a>xpath语法</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">表达式 说明</span><br><span class="line">article 选取所有article元素的所有子节点</span><br><span class="line">/article 选取根元素article</span><br><span class="line">article/a 选取所有属于article的子元素的a元素</span><br><span class="line">//div 选取所有div子元素（不论出现在文档任何地方）</span><br><span class="line">article//div 选取所有属于article元素的后代的div元素，不管它出现在article之下的任何位置</span><br><span class="line">//@class 选取所有名为class的属性</span><br><span class="line"></span><br><span class="line">/div/* 选取属于div元素的所有子节点</span><br><span class="line">//* 选取所有元素</span><br><span class="line">//div[@*] 选取所有带属性的title元素</span><br><span class="line">//div/a|//div/p 选取所有div元素的a和p元素</span><br><span class="line">//span|//ul 选取文档中的span和ul元素</span><br><span class="line">article/div/p|//span 选取所有属于article元素的div元素的p元素 以及文档中所有的span元素</span><br></pre></td></tr></table></figure>
<h5 id="xpath语法-谓语"><a href="#xpath语法-谓语" class="headerlink" title="xpath语法-谓语"></a>xpath语法-谓语</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">表达式 说明</span><br><span class="line">/article/div[1] 选取属于article子元素的第一个div元素</span><br><span class="line">/article/div[last()] 选取属于article子元素的最后一个div元素</span><br><span class="line">/article/div[last()-1] 选取属于article子元素的倒数第二个div元素</span><br><span class="line">//div[@lang] 选取所有拥有lang属性的div元素</span><br><span class="line">//div[@lang=&apos;eng&apos;] 选取所有lang属性为eng的div元素</span><br></pre></td></tr></table></figure>
<h5 id="scrapy-shell"><a href="#scrapy-shell" class="headerlink" title="scrapy shell"></a>scrapy shell</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scrapy shell http://blog.jobbole.com/110287</span><br><span class="line"></span><br><span class="line">title = response.xpath(&quot;//div[@class=&apos;entry-header&apos;]/h1/text()&quot;)</span><br><span class="line"></span><br><span class="line">title</span><br><span class="line"></span><br><span class="line">title.extract()</span><br></pre></td></tr></table></figure>
<h4 id="css选择器"><a href="#css选择器" class="headerlink" title="css选择器"></a>css选择器</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">表达式 说明</span><br><span class="line">* 选择所有节点</span><br><span class="line">#container 选择id为container的节点</span><br><span class="line">.container 选择所有class包含container的节点</span><br><span class="line">li a 选择所有li下的所有a节点</span><br><span class="line">ul + p 选择ul后面的第一个p元素</span><br><span class="line">div#container &gt; ul 选取id为container的div的第一个ul子元素</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">表达式 说明</span><br><span class="line">ul ～ p 选取与ul相邻的所有p元素</span><br><span class="line">a[title] 选取所有有title属性的a元素</span><br><span class="line">a[href=&quot;http://jobbole.com&quot;] 选取所有href属性为jobbole.com值的a元素</span><br><span class="line">a[href*=&quot;jobbole&quot;] 选取所有href属性包含jobbole的a元素</span><br><span class="line">a[href^=&quot;http&quot;] 选取所有href属性值以http开头的a元素</span><br><span class="line">a[href$=&quot;.jpg&quot;] 选取所有href属性值以.jpg结尾的a元素</span><br><span class="line">input[type=radio]:checked 选择选中的radio的元素</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">表达式 说明</span><br><span class="line">div:not(#container) 选取所有id非container的div属性</span><br><span class="line">li:nth-child(3) 选取第三个li元素</span><br><span class="line">tr:nth-child(2n) 第偶数个tr</span><br></pre></td></tr></table></figure>
<h5 id="scrapy-shell-1"><a href="#scrapy-shell-1" class="headerlink" title="scrapy shell"></a>scrapy shell</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scrapy shell http://blog.jobbole.com/110287</span><br><span class="line"></span><br><span class="line">title = response.css(&quot;.entry-header h1::text&quot;)</span><br><span class="line"></span><br><span class="line">title</span><br><span class="line"></span><br><span class="line">title.extract()</span><br></pre></td></tr></table></figure>
<h4 id="scrapy-http"><a href="#scrapy-http" class="headerlink" title="scrapy.http"></a>scrapy.http</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from scrapy.http import Request</span><br></pre></td></tr></table></figure>
<h4 id="scrapy-djangoitem"><a href="#scrapy-djangoitem" class="headerlink" title="scrapy-djangoitem"></a>scrapy-djangoitem</h4><h4 id="item-loader-jobbole-py"><a href="#item-loader-jobbole-py" class="headerlink" title="item-loader jobbole.py"></a>item-loader jobbole.py</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.loader <span class="keyword">import</span> ItemLoader</span><br><span class="line"><span class="comment"># 通过item_loader加载item,JobboleArticleItem()是item.py里的item。</span></span><br><span class="line">item_loader = ItemLoader(item=JobboleArticleItem(), response=response)</span><br><span class="line">item_loader.add_css(<span class="string">"title"</span>, <span class="string">".entry-header h1::text"</span>)</span><br><span class="line">item_loader.add_xpath()</span><br><span class="line">item_loader.add_value(<span class="string">"url"</span>, response.url)</span><br><span class="line"><span class="comment"># 重新加载</span></span><br><span class="line">article_item = item_loader.load_item()</span><br><span class="line"><span class="comment"># 传出</span></span><br><span class="line"><span class="keyword">yield</span> article_item</span><br></pre></td></tr></table></figure>
<h4 id="item-py"><a href="#item-py" class="headerlink" title="item.py"></a>item.py</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">class JobBoleArticleItem(scrapy.Item):</span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    create_date = scrapy.Field(</span><br><span class="line">        input_processor=MapCompose(date_convert),</span><br><span class="line">    )</span><br><span class="line">    content = scrapy.Field()</span><br></pre></td></tr></table></figure>
<h2 id="第5章-scrapy爬取知名问答网站"><a href="#第5章-scrapy爬取知名问答网站" class="headerlink" title="第5章 scrapy爬取知名问答网站"></a>第5章 scrapy爬取知名问答网站</h2><hr>
<p>本章主要完成网站的问题和回答的提取。本章除了分析出问答网站的网络请求以外还会分别通过requests和scrapy的FormRequest两种方式完成网站的模拟登录， 本章详细的分析了网站的网络请求并分别分析出了网站问题回答的api请求接口并将数据提取出来后保存到mysql中。</p>
<hr>
<h4 id="cookie"><a href="#cookie" class="headerlink" title="cookie"></a>cookie</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">distributed_crawler_search_engine</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy shell -s &quot;输入headers&quot;</span><br></pre></td></tr></table></figure>
<p>知乎数据库设计</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">名 类型</span><br><span class="line">zhihu_id bigint 20 0 yes primay key 1</span><br><span class="line">url varchar 300 0 yes</span><br><span class="line">question_id bigint 20 0 yes</span><br><span class="line">author_id varchar 100 0 no</span><br><span class="line">content longtext 0 0 yes</span><br><span class="line">praise_num int 11 0 yes</span><br><span class="line">comments_num int 11 0 yes</span><br><span class="line">create_time date 0 0 yes</span><br><span class="line">update_time date 0 0 yes</span><br><span class="line">crawl_time datetime 0 0 yes</span><br><span class="line">crawl_update_time datetime 0 0 no</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> zhihu_question(<span class="string">`zhihu_id`</span> </span><br><span class="line"> )</span><br></pre></td></tr></table></figure>
<h2 id="第6章-通过CrawlSpider对招聘网站进行整站爬取"><a href="#第6章-通过CrawlSpider对招聘网站进行整站爬取" class="headerlink" title="第6章 通过CrawlSpider对招聘网站进行整站爬取"></a>第6章 通过CrawlSpider对招聘网站进行整站爬取</h2><h4 id="本章完成招聘网站职位的数据表结构设计，并通过link-extractor和rule的形式并配置CrawlSpider完成招聘网站所有职位的爬取，本章也会从源码的角度来分析CrawlSpider让大家对CrawlSpider有深入的理解。"><a href="#本章完成招聘网站职位的数据表结构设计，并通过link-extractor和rule的形式并配置CrawlSpider完成招聘网站所有职位的爬取，本章也会从源码的角度来分析CrawlSpider让大家对CrawlSpider有深入的理解。" class="headerlink" title="本章完成招聘网站职位的数据表结构设计，并通过link extractor和rule的形式并配置CrawlSpider完成招聘网站所有职位的爬取，本章也会从源码的角度来分析CrawlSpider让大家对CrawlSpider有深入的理解。"></a>本章完成招聘网站职位的数据表结构设计，并通过link extractor和rule的形式并配置CrawlSpider完成招聘网站所有职位的爬取，本章也会从源码的角度来分析CrawlSpider让大家对CrawlSpider有深入的理解。</h4><h2 id="第7章-Scrapy突破反爬虫的限制"><a href="#第7章-Scrapy突破反爬虫的限制" class="headerlink" title="第7章 Scrapy突破反爬虫的限制"></a>第7章 Scrapy突破反爬虫的限制</h2><blockquote>
<p>本章会从爬虫和反爬虫的斗争过程开始讲解，然后讲解scrapy的原理，然后通过随机切换user-agent和设置scrapy的ip代理的方式完成突破反爬虫的各种限制。本章也会详细介绍httpresponse和httprequest来详细的分析scrapy的功能，最后会通过云打码平台来完成在线验证码识别以及禁用cookie和访问频率来降低爬虫被屏蔽的可能性。…</p>
</blockquote>
<h3 id="UA-用户代理"><a href="#UA-用户代理" class="headerlink" title="UA 用户代理"></a>UA 用户代理</h3><p>hellysmile/fake-useragent</p>
<h3 id="IP代理"><a href="#IP代理" class="headerlink" title="IP代理"></a>IP代理</h3><p>西刺代理 高匿ip代理<br>aivarsk/scrapy-proxies<br>scrapy-plugins/scrapy-crawlera #收费的<br>Tor</p>
<h3 id="验证码识别"><a href="#验证码识别" class="headerlink" title="验证码识别"></a>验证码识别</h3><p>tesseract-ocr<br>在线打码<br>人工打码<br><a href="http://www.yundama.com" target="_blank" rel="noopener">云打码</a></p>
<p>settings.py<br>禁用cookie<br>自动限速</p>
<p>爬虫内写入 ，自定义设置单个爬虫<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">custom_settings = &#123;</span><br><span class="line">	<span class="string">"COOKIES_ENABLED"</span>: <span class="keyword">True</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="第8章-scrapy进阶开发"><a href="#第8章-scrapy进阶开发" class="headerlink" title="第8章 scrapy进阶开发"></a>第8章 scrapy进阶开发</h2><blockquote>
<p>本章将讲解scrapy的更多高级特性，这些高级特性包括通过selenium和phantomjs实现动态网站数据的爬取以及将这二者集成到scrapy中、scrapy信号、自定义中间件、暂停和启动scrapy爬虫、scrapy的核心api、scrapy的telnet、scrapy的web service和scrapy的log配置和email发送等。 这些特性使得我们不仅只是可以通过scrapy来完成…</p>
</blockquote>
<p>Selenium浏览器自动化测试框架<br>浏览器Drivers</p>
<h2 id="第9章-scrapy-redis分布式爬虫"><a href="#第9章-scrapy-redis分布式爬虫" class="headerlink" title="第9章 scrapy-redis分布式爬虫"></a>第9章 scrapy-redis分布式爬虫</h2><h4 id="Scrapy-redis分布式爬虫的使用以及scrapy-redis的分布式爬虫的源码分析，-让大家可以根据自己的需求来修改源码以满足自己的需求。最后也会讲解如何将bloomfilter集成到scrapy-redis中。"><a href="#Scrapy-redis分布式爬虫的使用以及scrapy-redis的分布式爬虫的源码分析，-让大家可以根据自己的需求来修改源码以满足自己的需求。最后也会讲解如何将bloomfilter集成到scrapy-redis中。" class="headerlink" title="Scrapy-redis分布式爬虫的使用以及scrapy-redis的分布式爬虫的源码分析， 让大家可以根据自己的需求来修改源码以满足自己的需求。最后也会讲解如何将bloomfilter集成到scrapy-redis中。"></a>Scrapy-redis分布式爬虫的使用以及scrapy-redis的分布式爬虫的源码分析， 让大家可以根据自己的需求来修改源码以满足自己的需求。最后也会讲解如何将bloomfilter集成到scrapy-redis中。</h4><h2 id="第10章-elasticsearch搜索引擎的使用"><a href="#第10章-elasticsearch搜索引擎的使用" class="headerlink" title="第10章 elasticsearch搜索引擎的使用"></a>第10章 elasticsearch搜索引擎的使用</h2><h4 id="本章将讲解elasticsearch的安装和使用，将讲解elasticsearch的基本概念的介绍以及api的使用。本章也会讲解搜索引擎的原理并讲解elasticsearch-dsl的使用，最后讲解如何通过scrapy的pipeline将数据保存到elasticsearch中。"><a href="#本章将讲解elasticsearch的安装和使用，将讲解elasticsearch的基本概念的介绍以及api的使用。本章也会讲解搜索引擎的原理并讲解elasticsearch-dsl的使用，最后讲解如何通过scrapy的pipeline将数据保存到elasticsearch中。" class="headerlink" title="本章将讲解elasticsearch的安装和使用，将讲解elasticsearch的基本概念的介绍以及api的使用。本章也会讲解搜索引擎的原理并讲解elasticsearch-dsl的使用，最后讲解如何通过scrapy的pipeline将数据保存到elasticsearch中。"></a>本章将讲解elasticsearch的安装和使用，将讲解elasticsearch的基本概念的介绍以及api的使用。本章也会讲解搜索引擎的原理并讲解elasticsearch-dsl的使用，最后讲解如何通过scrapy的pipeline将数据保存到elasticsearch中。</h4><h2 id="第11章-课程总结"><a href="#第11章-课程总结" class="headerlink" title="第11章 课程总结"></a>第11章 课程总结</h2><h4 id="本章讲解如何通过django快速搭建搜索网站，-本章也会讲解如何完成django与elasticsearch的搜索查询交互。"><a href="#本章讲解如何通过django快速搭建搜索网站，-本章也会讲解如何完成django与elasticsearch的搜索查询交互。" class="headerlink" title="本章讲解如何通过django快速搭建搜索网站， 本章也会讲解如何完成django与elasticsearch的搜索查询交互。"></a>本章讲解如何通过django快速搭建搜索网站， 本章也会讲解如何完成django与elasticsearch的搜索查询交互。</h4><h2 id="第12章-scrapyd部署scrapy爬虫"><a href="#第12章-scrapyd部署scrapy爬虫" class="headerlink" title="第12章 scrapyd部署scrapy爬虫"></a>第12章 scrapyd部署scrapy爬虫</h2><h4 id="本章主要通过scrapyd完成对scrapy爬虫的线上部署。"><a href="#本章主要通过scrapyd完成对scrapy爬虫的线上部署。" class="headerlink" title="本章主要通过scrapyd完成对scrapy爬虫的线上部署。"></a>本章主要通过scrapyd完成对scrapy爬虫的线上部署。</h4><h2 id="第13章-课程总结"><a href="#第13章-课程总结" class="headerlink" title="第13章 课程总结"></a>第13章 课程总结</h2><h4 id="重新梳理一遍系统开发的整个过程，-让同学对系统和开发过程有一个更加直观的理解"><a href="#重新梳理一遍系统开发的整个过程，-让同学对系统和开发过程有一个更加直观的理解" class="headerlink" title="重新梳理一遍系统开发的整个过程， 让同学对系统和开发过程有一个更加直观的理解"></a>重新梳理一遍系统开发的整个过程， 让同学对系统和开发过程有一个更加直观的理解</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install selenium redis elasticsearch_dsl PyMySQL requests</span><br></pre></td></tr></table></figure>

      
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Shell高级编程实战-目录" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2018/07/12/Shell高级编程实战-目录/" class="article-date">
      <time datetime="2018-07-12T05:51:19.279Z" itemprop="datePublished">2018-07-12</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h2 id="01-Shell高级编程实战（第一、二部）"><a href="#01-Shell高级编程实战（第一、二部）" class="headerlink" title="01.Shell高级编程实战（第一、二部）"></a>01.Shell高级编程实战（第一、二部）</h2><p>01.Shell编程课前思想-我一定要学好Shell编程.mp4 16:28<br>02.学好Shell编程需要的必备基础.mp4 15:03<br>03.Shell脚本介绍及第一个规范Shell脚本说明.mp4 29:00<br>04.Shell编程的作用和地位.mp4 05:59<br>05.Shell语言的种类介绍.mp4 05:03<br>06.Shell的条件表达式知识初步介绍实践.mp4 22:50<br>07.Shell的字符串表达式介绍-实践及企业案例脚本剖析.mp4 16:09<br>08.Shell的整数表达式介绍-实践及企业案例脚本剖析.mp4 14:39<br>09.Shell的逻辑操作符知识介绍-实践及企业案例脚本剖析.mp4 11:10<br>10.Shell的各种表达式综合脚本开发实战讲解.mp4 20:29<br>11.利用所学知识打印一二级菜单操作企业案例.mp4 17:48<br>12.if条件句语法介绍及形象比喻.mp4 12:01<br>13.监控系统内存并报警企业案例脚本开发实战.mp4 24:13<br>14.利用if监控web和db的多种方法介绍及实践1.mp4 21:02<br>15.利用if监控web和db的多种方法介绍及实践2.mp4 44:00<br>16.Shell课堂学生拿到OFFER分享.mp4 16:06<br>17.Shell分组学习规划.mp4 22:02<br>18.课后作业.mp4 02:50</p>
<h2 id="02-Shell高级编程实战（第三、四部）"><a href="#02-Shell高级编程实战（第三、四部）" class="headerlink" title="02.Shell高级编程实战（第三、四部）"></a>02.Shell高级编程实战（第三、四部）</h2><p>01.课前提问上节知识与内容回顾.mp4 16:23<br>02.Shell的数值运算深度实践4.mp4<br>03.Shell的数值运算知识深度实践5.mp4<br>04.变量的读入之read知识及实战脚本开发.mp4<br>05.Shell的条件表达式知识初步介绍实践.mp4<br>06.Shell的条件表达式知识初步介绍实践.mp4<br>07.Shell的字符串表达式介绍-实践及企业案例脚本剖析.mp4<br>08.Shell的整数表达式介绍-实践及企业案例脚本剖析.mp4<br>09.Shell的逻辑操作符知识介绍-实践及企业案例脚本剖析.mp4<br>10.Shell的各种表达式综合脚本开发实战讲解.mp4<br>11.利用所学知识打印一二级菜单操作企业案例.mp4<br>12.if条件句语法介绍及形象比喻.mp4<br>13.监控系统内存并报警企业案例脚本开发实战.mp4<br>14.利用if监控web和db的多种方法介绍及实践1.mp4<br>15.利用if监控web和db的多种方法介绍及实践2.mp4<br>16.Shell课堂学生拿到OFFER分享.mp4<br>17.Shell分组学习规划.mp4<br>18.课后作业.mp4</p>
<h2 id="03-Shell高级编程实战（第五、六部）"><a href="#03-Shell高级编程实战（第五、六部）" class="headerlink" title="03.Shell高级编程实战（第五、六部）"></a>03.Shell高级编程实战（第五、六部）</h2><p>01.课前思想-葛亮挥泪斩马谡.mp4 19:34<br>02.企业级增删改查用户脚本开发实战分享.mp4<br>03.Shell函数的介绍及实践.mp4<br>04.Shell的函数及函数传参实践.mp4<br>05.监控网站是否异常企业案例脚本开发手把手讲解.mp4<br>06.给任意字符串加指定颜色的企业级函数案例实战.mp4<br>07.shell的case语句介绍及案例实践.mp4<br>08.开发Nginx启动脚本并实现加入开机自启动管理实战.mp4<br>09.开发Nginx启动脚本并实现加入开机自启动管理实战-老男孩点评修改.mp4<br>10.case语句企业案例和系统脚本剖析.mp4<br>11.while循环介绍及实践.mp4<br>12.Shell脚本手机充值案例精讲.mp4<br>13.Shell脚本手机充值案例精讲后修改及点评.mp4<br>14.While循环读取日志分析的企业案例多种方法精讲.mp4<br>15.课后作业与下节内容预习说明.mp4</p>
<h2 id="04-Shell高级编程实战（第七、八部）"><a href="#04-Shell高级编程实战（第七、八部）" class="headerlink" title="04.Shell高级编程实战（第七、八部）"></a>04.Shell高级编程实战（第七、八部）</h2><h2 id="05-Shell高级编程实战（第九、十部）"><a href="#05-Shell高级编程实战（第九、十部）" class="headerlink" title="05.Shell高级编程实战（第九、十部）"></a>05.Shell高级编程实战（第九、十部）</h2><h2 id="06-Shell高级编程实战（第十一、十二部）"><a href="#06-Shell高级编程实战（第十一、十二部）" class="headerlink" title="06.Shell高级编程实战（第十一、十二部）"></a>06.Shell高级编程实战（第十一、十二部）</h2><h2 id="07-Shell高级编程实战（第十三部）三剑客之sed实践讲解"><a href="#07-Shell高级编程实战（第十三部）三剑客之sed实践讲解" class="headerlink" title="07.Shell高级编程实战（第十三部）三剑客之sed实践讲解"></a>07.Shell高级编程实战（第十三部）三剑客之sed实践讲解</h2><h2 id="08-Shell高级编程实战（第十四部）AWK数组国内企业案例"><a href="#08-Shell高级编程实战（第十四部）AWK数组国内企业案例" class="headerlink" title="08.Shell高级编程实战（第十四部）AWK数组国内企业案例"></a>08.Shell高级编程实战（第十四部）AWK数组国内企业案例</h2>
      
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Python分布式爬虫打造搜索引擎笔记" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2018/07/12/Python分布式爬虫打造搜索引擎笔记/" class="article-date">
      <time datetime="2018-07-12T05:51:19.279Z" itemprop="datePublished">2018-07-12</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>2018.03.19 20:01</p>
<p>作者博客<br><a href="http://projectsedu.com" target="_blank" rel="noopener">http://projectsedu.com</a><br>github.com/liyaopinner</p>
<p>IDE pycharm<br>数据库 mysql redis </p>
<p>Python 2.7.13<br>Python 3.5.3</p>
<p>第三章 基础知识</p>
<p>技术选型:<br>scrapy<br>requests<br>scrapy selector</p>
<p>网页分类：<br>静态网页<br>动态网页<br>微博service(rest api)</p>
<p>爬虫能做什么<br>1、搜索引擎-百度<br>2、推荐引擎-今日头条<br>3、机器学习的数据样本<br>4、数据分析、舆情分析</p>
<p>正则表达式<br>非贪婪模式 ？<br>至少出现一次 +<br>限定前面的字符出现的次数 {}<br>满足任意一个 []<br>\s 代表空格<br>\S 只要不是空格就行一个字符<br>\w 代表a-zA-Z0-9_ 代表字符<br>\W 不代表a-Z0-9_<br>\d 代表数字</p>
<p>深度优先和广度优先算法</p>
<p>深度优先 递归实现<br>广度优先 队列实现</p>
<p>数据结构里很重要的算法</p>
<p>深度优先过程</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">depth_tree</span><span class="params">(tree_node)</span>:</span></span><br><span class="line">	<span class="keyword">if</span> tree_node <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">		print(tree_node._data)</span><br><span class="line">		<span class="keyword">if</span> tree_node._left <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">			<span class="keyword">return</span> depth_tree(tree_node._left):</span><br><span class="line">		<span class="keyword">if</span> tree_node._right <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">			<span class="keyword">return</span> depth_tree(tree_node._right)</span><br></pre></td></tr></table></figure>
<p>广度优先过程</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">level_queue</span><span class="params">(root)</span>:</span></span><br><span class="line">	<span class="keyword">if</span> root <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	my_queue = []</span><br><span class="line">	node = root</span><br><span class="line">	my_queue.append(node)</span><br><span class="line">	<span class="keyword">while</span> my_queue:</span><br><span class="line">		node = my_queue.pop(<span class="number">0</span>)</span><br><span class="line">		print(node.elem)</span><br><span class="line">		<span class="keyword">if</span> node.lchild <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">			my_queue.append(node.lchild)</span><br><span class="line">		<span class="keyword">if</span> node.rchild <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">			my_queue.append(node.rchild)</span><br></pre></td></tr></table></figure>
<p>url去重策略</p>
<p>1、将访问过的url保存到数据库<br>2、将访问过的url保存到set中<br>3、url经过md5等方法哈希后保存到set中 scrapy使用的是这个方法<br>4、用bitmap方法，<br>5、bloomfilter方法对bitmap进行改进，多重hash函数降低冲突</p>
<p>unicode和utf8编码<br>内存中的数据都是unicode编码<br>python3中文件中存的数据是utf-8编码<br>所有编码解码 decode为unicode<br>uncode编码 encode为utf-8</p>
<p>获取系统默认的编码<br>sys.getdefaultencoding()</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-*- coding: utf<span class="number">-8</span> -*-</span><br></pre></td></tr></table></figure>
<p>scrapy爬取jobbole</p>
<p>pycharm 中调试scrapy</p>
<p>main.py main.py放在和scrapy.cfg同一目录</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy.cmdline <span class="keyword">import</span> execute</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找main.py的执行位置</span></span><br><span class="line">sys.path.append(os.path.dirname(os.path.abspath(__file__)))</span><br><span class="line"><span class="comment"># 执行爬虫</span></span><br><span class="line">execute([<span class="string">'scrapy'</span>, <span class="string">'crawl'</span>, <span class="string">'jobbole'</span>])</span><br></pre></td></tr></table></figure>
<p>xpath语法<br>div[@class=”goods-add fn-clear J-DAddToBag”]<br>//span[contains(@class, ‘J-DAddToBag’)]</p>
<p>/article/div[1] 选取属于article子元素的第一个div元素<br>/article/div[last()] 选取属于article子元素的最后一个div元素<br>/article/div[last()-1] 选取属于article子元素的倒数第二个div元素<br>//div/<em> 选取属于div元素的所有子节点<br>//div[@</em>] 选取所有带属性的title元素<br>/div/a|//div/p 选取所有div元素的a和p元素<br>//span|//ul 选取文档中的span和ul元素<br>article/div/p| //span 选取所有属于span元素的div元素的p元素以及文档中的所有的span元素</p>
<p>css selector语法<br>li a 选取所有li下的所有a元素<br>ul + p 选择ul后面的第一个p元素<br>div#container &gt; ul 选取id为container的div的第一个ul子元素<br>ul ~ p 选取与ul相邻的所有p元素<br>a[title] 选取所有有title属性的a元素<br>a[href=”<a href="http://jobbole.com&quot;]" target="_blank" rel="noopener">http://jobbole.com&quot;]</a> 选取所有href属性为jobbole.com值的a元素<br>a[href*=”jobbole”] 选取所有href属性包含jobbole.com的a元素<br>a[href^=”http”] 选取所有href属性以http开头的a元素<br>a[href$=”.jpg”] 选取所有href属性以.jpg结尾的a元素<br>input[type=radio]:checked 选择选中的radio的元素<br>div:not(#container) 选取所有id非container属性的div元素<br>li:nth-child(3) 选取第三个li元素<br>tr:nth-child(2n) 第偶数个tr</p>
<p>伪类选择器<br>h1::text<br>div h1::attr(href) </p>
<p>列表生成式<br>tag_list = [‘职场’, ‘1 评论’, ‘fuck两点水’]</p>
<p>[ element for element in tag_list if not element.strip().endswith(“评论”)]</p>
<p>正则表达式<br>fav_nums = “sssd123werwe”<br>match_re = re.match(“.<em>(\d+).</em>“, fav_nums)<br>if match_re:<br>    fav_nums = int(match_re.group(1))<br>else:<br>    fav_nums = 0</p>
<p>字符串方法<br>tags = “,”.join(‘12345’)        结果 ‘1,2,3,4,5’</p>
<p>response.xpath().extract() 需要异常处理<br>response.xpath().extract_first()</p>
<p>from scrapy.http import Request<br>Request(url=,callback=)</p>
<p>from urllib import parse<br>parse.urljoin()</p>
<p>meta<br>scrapy.Request(url=,meta={‘goodsid’:goodsid},callback=)<br>goodsid = response.meta.get(“goodsid”, “”)</p>
<p>scrapy 图片管道 imagespipeline <code>pip install pillow</code><br>settings.py<br>scrapy.pipelines.images.ImagesPipeLine<br>IMAGES_URLS_FIELD = “items.py 中的item,url需要是list类型”<br>project_dir = os.path.abspath(os.path.dirname(<strong>file</strong>))<br>IMAGES_STORE = os.path.join(project_dir, ‘images’)</p>
<p><a href="https://coding.imooc.com/lesson/92.html#mid=2878" target="_blank" rel="noopener">DIY pipeline</a><br>图片管道自定义<br>4-12 items设计-3 视频的02:12</p>
<p>ImagesPipeline<br>item_completed()</p>
<p>utils/<br><strong>init</strong>.py<br>common.py</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_md5</span><span class="params">(url)</span>:</span></span><br><span class="line">	<span class="keyword">if</span> isinstance(url, str):</span><br><span class="line">		url = url.encode(<span class="string">"utf-8"</span>)</span><br><span class="line">	m = hashlib.md5()</span><br><span class="line">	m.update(url)</span><br><span class="line">	<span class="keyword">return</span> m.hexdigest()</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">	print(get_md5(<span class="string">"http://www.baidu.com"</span>)</span><br></pre></td></tr></table></figure>
<p>数据保存<br>pipeline</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JsonPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">		self.file = codecs.open(<span class="string">'article.json'</span>, <span class="string">'w'</span>, encoding=<span class="string">"utf-8"</span>)</span><br><span class="line">		</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">	lines = json.dumps(dict(item), ensure_ascii=<span class="keyword">False</span>) + <span class="string">"\n"</span></span><br><span class="line">	self.write(lines)</span><br><span class="line">	<span class="keyword">return</span> item</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">            self.file.close()</span><br></pre></td></tr></table></figure>
<p>JsonItemExporter</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.exporters <span class="keyword">import</span> JsonItemExporter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JsonExporterPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">		self.file = open(<span class="string">'articleexporter.json'</span>, <span class="string">'wb'</span>)</span><br><span class="line">		self.exporter = JsonItemExporter(self.file, encoding=<span class="string">"utf-8"</span>, ensure_ascii=<span class="keyword">False</span>)</span><br><span class="line">		self.exporter.start_exporting()</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self. item, spider)</span>:</span></span><br><span class="line">		self.exporter.export_item(item)</span><br><span class="line">		<span class="keyword">return</span> item</span><br><span class="line">		</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">		self.exporter.finish_exporting()</span><br><span class="line">		self.file.close()</span><br></pre></td></tr></table></figure>
<p>数据库</p>
<p>新建数据库<br>新建数据表</p>
<p><img src="./jobbole_article_mysql.png" alt="jobbole_article_mysql"></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">create_date = <span class="string">'时间字符串'</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">	datetime.datetime.strptime(create_date, <span class="string">"%Y/%m/%d"</span>).date()</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">	create_date = datetime.datetime.now().date()</span><br></pre></td></tr></table></figure>
<p>pip install mysqlclient pymysql</p>
<p>同步插入mysql</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MysqlPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">		self.conn = pymysql.connect(<span class="string">'host'</span>, <span class="string">'user'</span>, <span class="string">'password'</span>, <span class="string">'port'</span>, <span class="string">'dbname'</span>, charset=<span class="string">"utf-8"</span>, use_unicode=Ture)</span><br><span class="line">		self.cursor = self.conn.cursor()</span><br><span class="line">		</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">		insert_sql = <span class="string">"""</span></span><br><span class="line"><span class="string">			insert into jobbole_article(title, url)</span></span><br><span class="line"><span class="string">			VALUES (%s,%s)"""</span></span><br><span class="line">		self.cursor.execute(insert_sql, (item[<span class="string">"title"</span>], item[<span class="string">"url"</span>])</span><br><span class="line">		self.conn.commit()</span><br></pre></td></tr></table></figure>
<p>异步插入mysql</p>
<p>连接池</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> twisted.enterprise <span class="keyword">import</span> adbapi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MysqlTwistedPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">		self.dbpool = dbpool</span><br><span class="line">	</span><br><span class="line"><span class="meta">	@classmethod</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">from_settings</span><span class="params">(cls, settings)</span>:</span></span><br><span class="line">		dbparms = dict(</span><br><span class="line">			host = settings[<span class="string">"MYSQL_HOST"</span>],</span><br><span class="line">			db = settings[<span class="string">"MYSQL_DBNAME"</span>],</span><br><span class="line">			user = settings[<span class="string">"MYSQL_USER"</span>],</span><br><span class="line">			password = settings[<span class="string">"MYSQL_PASSWORD"</span>],</span><br><span class="line">			charset = <span class="string">'utf-8'</span>,</span><br><span class="line">			cursorclass = pymysql.cursors.DictCursor,</span><br><span class="line">			use_unicode = <span class="keyword">True</span>,</span><br><span class="line">		)</span><br><span class="line">		dbpool = adbapi.ConnectionPool(<span class="string">"pymysql"</span>, **dbparms)</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">return</span> cls(dbpool)</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">		query = self.dbpool.runInteraction(do_insert, item)</span><br><span class="line">		query.addErrback(self.handle_error)</span><br><span class="line">		</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">handle_error</span><span class="params">(self, failure)</span>:</span></span><br><span class="line">		print(failure)</span><br><span class="line">		</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">do_insert</span><span class="params">(self, cursor, item)</span>:</span></span><br><span class="line">		insert_sql = <span class="string">"""</span></span><br><span class="line"><span class="string">			insert into jobbole_article(title, url)</span></span><br><span class="line"><span class="string">			VALUES (%s,%s)"""</span></span><br><span class="line">		cursor.execute(insert_sql, (item[<span class="string">"title"</span>], item[<span class="string">"url"</span>])</span><br></pre></td></tr></table></figure>
<p>scrapy-djangoitem</p>
<p>pip install scrapy-djangoitem</p>
<p>scrapy item loader 机制</p>
<p>itemloader会将所有提取的值变为list类型</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.loader <span class="keyword">import</span> ItemLoader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">item_loader = ItemLoader(item=JobboleItem(),response=response)</span><br><span class="line"></span><br><span class="line">itemloader.add_xpath()</span><br><span class="line">itemloader.add_css()</span><br><span class="line">itemloader.value()</span><br><span class="line"></span><br><span class="line">item = itemloader.load_item()</span><br><span class="line"></span><br><span class="line"><span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure>
<p>items.py</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.loader.processors <span class="keyword">import</span> MapCompose</span><br><span class="line"></span><br><span class="line"><span class="comment">#取第一个值</span></span><br><span class="line"><span class="keyword">from</span> scrapy.loader.processors <span class="keyword">import</span> TakeFirst，Join</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_jobbole</span><span class="params">(value)</span>:</span></span><br><span class="line">	<span class="keyword">return</span> value + <span class="string">"-jobbole"</span></span><br><span class="line">	</span><br><span class="line"></span><br><span class="line">title = scrapy.Field(</span><br><span class="line">	input_processor = MapCompose(add_jobbole)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">name = scrapy.Field(</span><br><span class="line">	input_processor = MapCompose(<span class="keyword">lambda</span> x:x+<span class="string">"-jinlong"</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">urls = scrapy.Field(</span><br><span class="line">	input_processor = MapCompose(<span class="keyword">lambda</span> x:x+<span class="string">"-kjj"</span>, add_jobbole)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">create_date = scrapy.Field(</span><br><span class="line">	input_processor = MapCompose(add_jobbole)</span><br><span class="line">	output_processor = TakeFirst()</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>自定义itemloader</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ArticleItemLoader</span><span class="params">(ItemLoader)</span>:</span></span><br><span class="line">	default_output_processor = TakeFirst()</span><br></pre></td></tr></table></figure>
<p>session和cookie自动登录机制<br>session服务器端<br>cookie客户端</p>
<p>settings.py<br>AUTOTHROTTLE_ENABLED = True</p>
<p>spider.py</p>
<p>custom_settings = {<br>    “COOKIES_ENABLED”: True<br>}</p>
<p>selenuim driver</p>
<p>ChromeDriver - WebDriver for Chrome</p>
<p><a href="https://sites.google.com/a/chromium.org/chromedriver/downloads" target="_blank" rel="noopener">https://sites.google.com/a/chromium.org/chromedriver/downloads</a></p>
<p>brew install chromedriver</p>
<p><a href="https://segmentfault.com/a/1190000013067705" target="_blank" rel="noopener">https://segmentfault.com/a/1190000013067705</a></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium.webdriver.chrome.options <span class="keyword">import</span> Options</span><br><span class="line">chrome_options = Options()</span><br><span class="line">chrome_options.add_argument(<span class="string">'window-size=1920x3000'</span>) <span class="comment">#指定浏览器分辨率</span></span><br><span class="line">chrome_options.add_argument(<span class="string">'--disable-gpu'</span>) <span class="comment">#谷歌文档提到需要加上这个属性来规避bug</span></span><br><span class="line">chrome_options.add_argument(<span class="string">'--hide-scrollbars'</span>) <span class="comment">#隐藏滚动条, 应对一些特殊页面</span></span><br><span class="line">chrome_options.add_argument(<span class="string">'blink-settings=imagesEnabled=false'</span>) <span class="comment">#不加载图片, 提升速度</span></span><br><span class="line">chrome_options.add_argument(<span class="string">'--headless'</span>) <span class="comment">#浏览器不提供可视化页面. linux下如果系统不支持可视化不加这条会启动失败</span></span><br><span class="line">chrome_options.binary_location = <span class="string">r'/Applications/Google Chrome Canary.app/Contents/MacOS/Google Chrome Canary'</span> <span class="comment">#手动指定使用的浏览器位置</span></span><br></pre></td></tr></table></figure>
      
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Python学习-老男孩系的学生们的博客" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2018/07/12/Python学习-老男孩系的学生们的博客/" class="article-date">
      <time datetime="2018-07-12T05:51:19.279Z" itemprop="datePublished">2018-07-12</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p><a href="http://www.cnblogs.com/yangjian1/p/5917621.html" target="_blank" rel="noopener">python基础之初始python</a></p>
<p><a href="http://www.cnblogs.com/allen-zhang/p/6114864.html" target="_blank" rel="noopener">Python之路,Day1 - Python基础1</a></p>

      
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Python开发者" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2018/07/12/Python开发者/" class="article-date">
      <time datetime="2018-07-12T05:51:19.279Z" itemprop="datePublished">2018-07-12</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>优秀Python开发者</p>
<p>Flask和Requests的作者<br>Celery作者Ask Solem<br>Django<br>kombu</p>
<p>爬虫<br>刚开始写爬虫用的是urllib2，后来知道了requests，惊为天人。刚开始解析网页用的是re，后来知道了BeautifulSoup，解析页面不能再轻松。再后来看别人的爬虫，知道了scrapy，被这个框架惊艳到了。之后遇到了一些有验证码的网站，于是知道了PIL。但后来知道了opencv，pybrain。当在爬虫中用上人工神经网络识别出验证码，兴奋得守在爬虫旁边看他爬完全站。再后来知道了threading，知道了celery。不断的学习，不断的接触和知道更多的东西，爬虫与反爬虫的对抗会一直进行下去。</p>
<p>作者：bsdr<br>链接：<a href="https://www.zhihu.com/question/38192299/answer/75884957" target="_blank" rel="noopener">https://www.zhihu.com/question/38192299/answer/75884957</a><br>来源：知乎<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
<p>requests<br>BeautifulSoup<br>opencv<br>pybrain<br>threading<br>celery</p>
<p>scrapy<br>selenium<br>phantomjs</p>
<p>python学习手册 第四版</p>
<p>python核心编程 第二版</p>
<p>开始不用学，进阶学习<br>ORM<br>ElasticSearch</p>
<p>不用存储，爬去数据发送邮件</p>
<p>抓去顺序</p>
<p>开放的API<br>手机APP的API<br>Android的API实现抓取知乎的数据<br>HTML</p>
<p>抓包工具<br>Charles</p>
<p>lxml<br>xpath</p>
<p>前端知识</p>
<p>运维-&gt;运维开发-&gt;Web开发-&gt;数据分析-&gt;需要数据写爬虫</p>

      
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/10/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/">9</a><a class="page-number" href="/page/10/">10</a><span class="page-number current">11</span><a class="page-number" href="/page/12/">12</a><a class="page-number" href="/page/13/">13</a><span class="space">&hellip;</span><a class="page-number" href="/page/36/">36</a><a class="extend next" rel="next" href="/page/12/">Next &raquo;</a>
    </nav>
  
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                &copy; 2018 幻舞梦境
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/luuman/hexo-theme-spfk" target="_blank">spfk</a> by luuman
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" >海贼到访数: 
                            <span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>, </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit">本页阅读量: 
                            <span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>

    </div>
    <script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script src="/js/main.js"></script>

    <script>
        $(document).ready(function() {
            var backgroundnum = 24;
            var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
            $("#mobile-nav").css({"background-image": backgroundimg,"background-size": "cover","background-position": "center"});
            $(".left-col").css({"background-image": backgroundimg,"background-size": "cover","background-position": "center"});
        })
    </script>


<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-39498261-3', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->



	<script>
	var _hmt = _hmt || [];
	(function() {
	  var hm = document.createElement("script");
	  hm.src = "//hm.baidu.com/hm.js?1bb44bf25fea8f000a1397f9b5438de7";
	  var s = document.getElementsByTagName("script")[0]; 
	  s.parentNode.insertBefore(hm, s);
	})();
	</script>


<div class="scroll" id="scroll">
    <a href="#"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments"><i class="fa fa-comments-o"></i></a>
    <a href="#footer"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    $(document).ready(function() {
        if ($("#comments").length < 1) {
            $("#scroll > a:nth-child(2)").hide();
        };
    })
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

  <script language="javascript">
    $(function() {
        $("a[title]").each(function() {
            var a = $(this);
            var title = a.attr('title');
            if (title == undefined || title == "") return;
            a.data('title', title).removeAttr('title').hover(

            function() {
                var offset = a.offset();
                $("<div id=\"anchortitlecontainer\"></div>").appendTo($("body")).html(title).css({
                    top: offset.top - a.outerHeight() - 15,
                    left: offset.left + a.outerWidth()/2 + 1
                }).fadeIn(function() {
                    var pop = $(this);
                    setTimeout(function() {
                        pop.remove();
                    }, pop.text().length * 800);
                });
            }, function() {
                $("#anchortitlecontainer").remove();
            });
        });
    });
</script>


  </div>
</body>
</html>